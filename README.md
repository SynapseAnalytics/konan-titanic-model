# konan-titanic-model

[Konan](https://konan.ai) is your one-stop platform to bring your AI models to life. Typically, one would be required to do some tedious boring work in order to prepare the machine learning or data science model for deployment. Not with us! With **Konan**, gone are the days of worrying about a model's *dependencies*, battling with *containerization* or obsessively hand-holding the *infrastructure*. This repo will guide you in preparing your machine learning model in as seamless a manner as possible! Of course, don't forget to also checkout **Konan's** rich [documentation](https://docs.konan.ai) for additional info.

This repository contains the source code and tooling necessarily to generate the `konan-titanic-model` docker image, a **Konan**-ready ML model packaged and distributed as a Docker image. The model aims to estimate the sale price of house based on the popular [Titanic Dataset](https://www.kaggle.com/competitions/titanic/data) and the Jupyter [notebook](https://www.kaggle.com/code/startupsci/titanic-data-science-solutions/notebook) titled *Titanic Data Science Solutions*, generously provided to the public by [Manav Sehgal](https://www.kaggle.com/startupsci).

You can also find the built image and its tags on [Dockerhub](https://hub.docker.com/r/konanai/konan-titanic-model) directly.

## Directory Structure

- `notebook.ipynb` contains the original Jupyter [notebook](https://www.kaggle.com/code/startupsci/titanic-data-science-solutions/notebook) as provided by [Manav Sehgal](https://www.kaggle.com/startupsci). It is used as a reference for the `python` scripts produced by this repo in the `titanic/src/playground` directory.
- The `.konan.example` environment file is provided as a template for end users, should they wish to replicate building this repository and generate a different **Konan**-compatible docker image from it.
- `build.sh` is the script that the Github Workflow for this repo uses to generate the new ML-model to be used in the docker images.
- The `tests/` directory contains the unit and integration tests that the Github Workflow will use to test any new changes added to the repo.
- The `data/` directory contains the datasets used by this repository
  - The `data/kaggle` directory contains a copy of the original [Titanic Dataset](https://www.kaggle.com/competitions/titanic/data), sourced from **Kaggle** directly.
  - The `data/final` directory contains cleaned `.csv` files that are **Konan**-compatible. In particular, some columns are renamed, others are dropped. This is the dataset that is used to `train`, `validate` and `test` the **Konan**-models generated by this repo.
  - The `data/metadata.yml` file contains some crucial information for the .encoding used by the ML-model.
- `titnaic` is the main directory for the repo. Some highlights about its contents include:
  - The `titnaic/retrain.sh` script file includes the command to trigger a **Model Retraining** on **Konan** for the generated model.
    - Check [konan-docs](https://docs.konan.ai/model-retraining) for more information on **Model Retraining**.
  - The `titanic/src/playground` directory contains the `python` scripts that generates the cleaned datasets (`data/final/*` files), given the original datasets from Kaggle. (`data/kaggle/*` files) and the `data/metadata.yml` file.
  - The `titanic/src/app` directory contains the `python` scripts for the **Konan** model's web-server, including the `retrain.py` and `server.py` files.
    - Check [konan-docs](https://docs.konan.ai/getting-started/quick-start) for more information on the requirements for generating a **Konan Model**.
  - The `titanic/src/serving` directory contains `python` scripts that uses `konan-sdk` to interact with a **Konan** deployment created using a `konan-titanic-model` image.
    - Check the [documentation](https://konan-sdk.readthedocs.io/en/stable/) of `konan-sdk` to learn more about how to use it.
    - Make sure to generate a `.env` file from the provided `.env.example` example file.

## Usage

To ensure that your local environment contains all of the required dependencies, run `poetry install` to install the dependencies in a virtual environment. You can learn more about **poetry** [here](https://python-poetry.org).

### Deploying on Konan

1. Go to the [Dockerhub page](https://hub.docker.com/r/konanai/konan-titanic-model/tags) for this image and select the tag you want to deploy, and make note of the *image url*. The *image url* of your chosen tag is the part after the corresponding `docker pull`.
    - For example, if you are using the `latest` tag, then the *image url* will be:

        ```bash
        konanai/konan-titanic-model:latest
        ```

    - Don't forget to update the `latest` tag. It is always recommended to use a specific, versioned tag and **not** `latest`.
2. Go to [Konan](https://app.konan.ai), login and deploy this image as a new Deployment! Perhaps you'd find the relevant instructions on [Konan docs](https://docs.konan.ai/guide-to-konan-deployments/deploying-on-konan) useful.
    - Use the `image url` that you took note of in the previous step.
    - Leave the Container Registry Credentials blank, as you are using a publicly-available image.

### Using a deployed Konan Deployment

After following **Konan**'s [documentation](https://docs.konan.ai/guide-to-konan-deployments/deploying-on-konan) on deploying the `konan-titanic-model` on `Konan`, you may wish to use the provided `titanic/src/serving/main.py` script to interact with your newly-created deployment.

1. Log in to [Konan](https://app.konan.ai) and retrieve the `UUID` of the **Deployment** you created using the `konan-titanic-model`.
2. Create a `.env` file in the `titanic/src/serving` directory using the provided `.env.example` example file there.
3. Export the needed environment variables

    ```bash
    . ./titanic/src/serving/.env
    ```

4. Trigger some predictions and provide their feedback using the `titanic/src/serving/main.py` script file

    ```bash
    python titanic/src/serving/main.py
    ```

### Generating the cleaned datasets

```bash
python titanic/src/playground/prepare.py
```

### Training a new ML-model

1. Export some needed environment variables
  
    ```bash
    export KONAN_MODEL_CLASSIFIER_NAME="knn"  # only knn and gaussian are currently supported
    ```

2. Create an empty `artifacts/<ml-algorithm>` directory

    ```bash
    mkdir -p artifacts/"knn"  # must match the name of the above classifier name
    ```

3. Run the `train` script

    ```bash
    python titanic/src/playground/train.py
    ```

### Validating a trained model

1. Ensure you have trained the model, as described in the above steps
2. Export the same needed environment variables, with the same values
  
    ```bash
    export KONAN_MODEL_CLASSIFIER_NAME="knn"  # only knn and gaussian are currently supported
    ```

3. Run the `validate` script

    ```bash
    python titanic/src/playground/validate.py
    ```

### Building the Docker image

Although you may use the official **Konan** docker image for your use, you may of course use the provided source to build (and optionally) publish your own version of the docker image.

1. Create a `.konan` environment variable from the provided `.konan.example` example, and don't forget to update it with your container registry credentials and desired image name and tag.
2. Use the `Makefile` to build the image

    ```bash
    make build
    ```

3. Use the `Makefile` to login to Dockerhub

    ```bash
    make repo-login
    ```

4. Use the `Makefile` to publish the image

    ```bash
    make publish-version
    ```

Of course, feel free to run `make --help` to familiarize yourself with the other options the `Makefile` provides.

## Contributing

You are more than welcome to contribute to this repo's source code, documentation, and tooling scripts. We ask, however, that you keep your commits self-contained and to adhere to the [conventional commits](https://www.conventionalcommits.org/en/v1.0.0/) standard. This helps us automate pushing new tags and builds through [semantic versioning](https://semver.org).

## Support

If you have any questions, or feel that this repo needs some improvement, feel free to raise an **issue** with the repository's [Issue Tracker](https://github.com/SynapseAnalytics/konan-titanic-model/issues).
